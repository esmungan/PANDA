{"cells":[{"metadata":{"_uuid":"8ac9eb93-282a-4b75-a443-2050947fb83e","_cell_guid":"e3e0d494-bdc1-4d21-b6e4-5707056e9f48","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pathlib,os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport skimage.io\nfrom sklearn.model_selection import StratifiedKFold\nimport time\nimport albumentations\nimport tensorflow_addons as tfa\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers,models\n\nAUTO = tf.data.experimental.AUTOTUNE\n\nimport random as python_random\nnp.random.seed(123)\npython_random.seed(123)\ntf.random.set_seed(1234)\nos.environ['PYTHONHASHSEED']=str(0)\n\nimport cv2\nimport IPython.display as display\nfrom google.cloud import storage\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b904a1e0-d4ff-4136-afab-c01777a8fb8b","_cell_guid":"be8e4e77-1ab9-454e-a44d-2ac7a859da96","trusted":true},"cell_type":"code","source":"kaggle_data= '../input/prostate-cancer-grade-assessment'\n\ndata_dir=kaggle_data+'/train_images'\nds_dir = pathlib.Path(data_dir)\n\nlabel_dir=kaggle_data+'/train.csv'\ntrain_labels = pd.read_csv(label_dir).set_index('image_id')\n\ntest_path=kaggle_data+'/test_images'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88784c63-6d35-4bad-bf02-51763d60860f","_cell_guid":"7c27549d-8050-4c4c-9dd4-42a7df293d3f","trusted":true},"cell_type":"code","source":"black_list= ['3790f55cad63053e956fb73027179707','014006841b9807edc0ff277c4ab29b91','00d8a8c04886379e266406fdeff81c45','6f310463d3868e86be87adddeccdde19', '6ef357192c2530ee54e1bd38a3231e00', '511a33b7aeb1153407ed2d55cae001c8', '2fb68d6713a52e322692dbc99ac82444', '8a415b0e974861fa00ae9d88f9e3b980', 'eda92317b583435a810cac1dc7bb8025', 'c9dbdd9c9fc0eab0d235499488b26c53', '99d9afb22b65ea97fcd21ce67e1ddb6c', '0c46c60ae2ef49657bc843707162ba6e', '85b7018a9e5287342a1392fb02ce24a1', '4e80b5738f591c7d0d91889c2bdfd39d', 'f13cd8ec6e6fde523a0a065b62086d3c', 'aebe292567e0f8447fdc94994189a80a', '6b512a45bd8ca759e655c2d551dec2d9', 'be403ce415609008605d63396869ed2e', 'e3360926180928287a4d96973e10926a', '3752b697cae9f81a9d5ffe44dac58e7a', 'a0ac3589042f9e99d31b521b5b56ac06', 'f5675cb89a120e225ca8929b64a5af79', '6d569809f11e6e53918dfb1609fb0d83', '7817ae2d392ba4f6cb9104fbe70b6274', 'cd382fdc26516c634b2314aa870bfe80', '1cdd6def1e3099a9763938457cf0b4be', '0186f4811c9d089707d9dc7460160d88', 'e9d628364cf51891028163e0cfca628c', '9effeea56c413b92340b89d1240769c1', '7a0a36bc6119e3d78474e6c8ca875725', '374d5401159d9bf39ce20b395d82c0b4', '7fa4634ab59a7832bc877fef162eacaa', 'ee182a14e532b122f40d561d87eb2136', 'c0a0956a39319920d02c5c4eb30c5e10', '441265c6b4598e9bcd10bc10eb6293cc', '8ae069858aecbad846f4d69d405f9bd6', 'b13961504ea859ff34a150bc19fed335', '476f0dfb144aee7d5422dcc3b2b97a9f', 'bc93d165d96e4fa4883f130b3f7b9885', 'ac9d05fa3f4fafb474fb96f9f8ab71ac', '1438f19e07c389b47fd5219ca62f9f0a', '479200a381febadfd767615fbe77c3ea', 'fc6a695ba44f4b64425c522f590bac48', '046bac77a58c1be84a6418904e755280', '5c083ab21fc57c0954468ab46aa7fb16', 'cca735c397880e88192e97d68b97754e', 'a579110fe1e670847d9d146404597750', '8dbedd97ed2b7b01525d6800d52ae073', '004dd32d9cd167d9cc31c13b704498af', 'cdf40333dfe2afec1a4c54d9eeb1ec7a', '09d4be69a2330cd49298bf30d29cc4e5', 'f73951fddf77034c9fd44cb19f5fe6b5', 'aef75d4c390d838aabe56e2d601b6a13', 'b3a2dc7547bc580c6f3923c61db42051', '774c9b631a29f191836b1078a6c3a67c', '836ca5d73c88ad94fb980ca3e5e65da7', 'bfdbe56fb7fc4d7b3d151370f897d503', '06ef49a7b77e883f089cfdd80642d6f0', '8e25584bd03155d24a2adc00517a38e8', 'dc2ec851fcbf594f11b023387ac15003', 'a0150f4d6d9f6f3b2b5a240b099df000']\ntrain_labels=train_labels.drop(black_list)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09b1e21c-960f-450b-8126-84536a848e78","_cell_guid":"0b01aca0-6a68-4fd7-b5fe-dc9f0397fe06","trusted":true},"cell_type":"code","source":"def read_tiff(img_path,level):      \n    \n    #read the image and get the label\n    img      = skimage.io.MultiImage(str(img_path))[level]\n    im_ID    = img_path.split(os.sep)[-1].split('.')[0]\n    label    = train_labels.loc[im_ID,'isup_grade']        # get the label from the csv file\n                                                           # make sure the output type is updated in open_crop_tiff                                                           \n    return img, label, im_ID\n\ndef augment(image_array):\n    \n    # Augmentations    \n    op_train = albumentations.Compose([\n        albumentations.VerticalFlip(p=0.5),\n        albumentations.HorizontalFlip(p=0.5),\n        albumentations.Rotate(limit=90,border_mode=4,p=0.5),    #mode 1 wraps around\n        #albumentations.ElasticTransform(alpha=1, sigma=50, alpha_affine=50,p=0.5),\n        albumentations.HueSaturationValue(hue_shift_limit=(0,20), sat_shift_limit=0, val_shift_limit=0,p=0.5),\n        #albumentations.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20,p=0.5),\n        albumentations.GaussianBlur(blur_limit=3,p=0.25)\n    ])  \n    \n    return op_train(image=image_array)['image']        \n\n\ndef tile_tiff(img,level,n_tiles):\n    # get the patches with tissue    \n    \n    if (level==1): tile_size=256                          # tile size depends on the downsampling of the level\n    elif (level == 2): tile_size =128\n    else: raise Exception(\"level is not 1 or 2\")\n    \n    mode=0\n    sub_imgs=False\n    is_rand=False\n    \n    tiles = []\n    h, w, c = img.shape\n    pad_h = (tile_size - h % tile_size) % tile_size + ((tile_size * mode) // 2)\n    pad_w = (tile_size - w % tile_size) % tile_size + ((tile_size * mode) // 2)\n\n    img2 = np.pad(img,[[pad_h // 2, pad_h - pad_h // 2], [pad_w // 2,pad_w - pad_w//2], [0,0]], constant_values=255)\n    img3 = img2.reshape(img2.shape[0] // tile_size,tile_size,img2.shape[1] // tile_size,tile_size, 3)\n    \n    img3 = img3.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size,3)\n    n_tiles_with_info = (img3.reshape(img3.shape[0],-1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n    if len(img) < n_tiles:\n        img3 = np.pad(img3,[[0,N-len(img3)],[0,0],[0,0],[0,0]], constant_values=255)\n    idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:n_tiles]\n    img3 = img3[idxs]\n    for i in range(len(img3)):\n        tiles.append({'img':img3[i], 'idx':i})\n    \n    # create the patchwork  \n    if is_rand:\n        idxes = np.random.choice(list(range(n_tiles)), n_tiles, replace=False)\n    else:\n        idxes = list(range(n_tiles))\n    idxes = np.asarray(idxes) + n_tiles if sub_imgs else idxes\n\n    n_row_tiles = int(np.sqrt(n_tiles))\n    images = np.zeros((tile_size * n_row_tiles, tile_size * n_row_tiles, 3))\n    for h in range(n_row_tiles):\n        for w in range(n_row_tiles):\n            i = h * n_row_tiles + w\n    \n            if len(tiles) > idxes[i]:\n               this_img = tiles[idxes[i]]['img']\n            else:\n                this_img = np.ones((tile_size, tile_size, 3)).astype(np.uint8) * 255\n            this_img = 255 - this_img\n            h1 = h * tile_size\n            w1 = w * tile_size\n            images[h1:h1+tile_size, w1:w1+tile_size] = this_img\n\n    images = 255 - images\n    #images = images.astype(np.float32)\n    #images /= 255                                              # can't send as string  if I convert to float\n    \n    return images\n    \ndef tile_and_aug_tiff(img_path_tensor,level=1,aug=1,n_tiles=36):      # combining three python functions to be wrapped\n    \n    #read and get the label\n    img,label,im_ID = read_tiff(img_path_tensor,level)\n    \n    # Augment the image\n    if(aug): img= augment(img)\n\n    # get the patches with tissue    \n    images=tile_tiff(img,level,n_tiles)\n    \n    return images,label,im_ID","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b8f64c2-d273-4c51-bf3a-ae66cb8c8f25","_cell_guid":"9e65b290-a2e5-43a2-a642-2211e816ca4a","trusted":true},"cell_type":"code","source":"def create_folds(train_labels,n_fold,debug=0):\n    input_DF= train_labels.copy().reset_index(drop=False) # drop the image_ID as the index so that the you can index with skf's results\n\n    skf=StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n    for f, (train_idx,test_idx) in enumerate(skf.split(input_DF,input_DF['isup_grade'])):\n        input_DF.loc[test_idx,'test_fold']= f  #setting wrt test data indexes as they don't overlap\n\n    if debug: display(input_DF)    \n    \n    return input_DF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_list(fold, labels_DF,debug=0):\n\n    train_list=[]\n    im_ID_train=labels_DF.loc[:,'image_id']\n    for ID in im_ID_train:   train_list.append(os.path.join(data_dir,ID+'.tiff')) # changed from data_simple to data dir\n    if(debug): \n        print('train')\n        for i in train_list[0:2]: print(i)\n        print(\"Num of samples: \",len(train_list),\"\\n\")\n\n    return train_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The following functions can be used to convert a value to a type compatible\n# with tf.Example.\ndef _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef _float_feature(list_of_floats): # float32\n  return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n\n#=========================================\n\ndef image_example(image_string, label,im_ID_bytes):\n  \"\"\"\n  Creates a tf.Example message ready to be written to a file.\n  \"\"\"\n\n  image_feature_description = {\n      \"image\": _bytes_feature(image_string),\n      \"label\": _int64_feature(label),\n      \"im_ID\": _bytes_feature(im_ID_bytes)\n      }\n\n  return tf.train.Example(features=tf.train.Features(feature=image_feature_description))\n\n#=========================================\n\ndef to_tfrecord(rec_file,path_list,level,aug,n_tiles):\n    \n    with tf.io.TFRecordWriter(rec_file) as writer:\n\n      for img_path in tqdm(path_list):\n        \n        img,label,im_ID= tile_and_aug_tiff(img_path,level,aug,n_tiles)    \n        image_string = cv2.imencode('.png', img, [cv2.IMWRITE_PNG_COMPRESSION,1])[1].tostring()   #0-9 compression 0 =no compression, 1 optimum speed/size\n        #image_string = cv2.imencode('.tiff', img,[cv2.IMWRITE_TIFF_COMPRESSION,1])[1].tostring()   # compression code 1 stands for LZW\n        im_ID_bytes=tf.compat.as_bytes(im_ID)\n        \n        tf_example = image_example(image_string, label,im_ID_bytes)         # storing all the features in the tf.Example message.\n        writer.write(tf_example.SerializeToString())            # write the example messages to a file named images.tfrecords\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_tfrecord(example):\n    features = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n        \"label\": tf.io.FixedLenFeature([], tf.int64),   # shape [] means scalar\n        \"im_ID\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n    }\n    # decode the TFRecord\n    example = tf.io.parse_single_example(example, features)\n    image = tf.image.decode_png(example['image'], channels=0)  \n    image = tf.reverse(image, axis=[-1])\n    image = tf.image.convert_image_dtype(image, tf.float32)           #augmentation can't handle the normalization here\n\n    label = example['label']\n    im_ID = example['im_ID']\n    return image, label, im_ID\n\ndef display_9_images_from_dataset(dataset):\n  plt.figure(figsize=(13,13))\n  subplot=331\n  for i, (image, label,im_ID) in enumerate(dataset):\n    plt.subplot(subplot)\n    plt.axis('off')\n    plt.imshow(image.numpy())\n    plt.title(im_ID.numpy().decode(\"utf-8\"), fontsize=14,color='w')\n    subplot += 1\n    if i==8:\n      break\n  plt.tight_layout()\n  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n  plt.show()   \n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_DF=create_folds(train_labels,n_fold=5)\ntrain_list =get_list(fold=0, labels_DF=input_DF,debug=0)\ntrain_list_small=train_list[0:9]\nprint(train_list_small)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define a filename to store preprocessed image data:\nrecord_file = 'images.tfrecords'\nlevel=1\nfile_list=train_list_small\nlist_DF=train_labels\naug=1\nn_tiles=36\n\nto_tfrecord(record_file,file_list,level,aug,n_tiles)\n!du -sh {record_file}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to read TFRecord file use TFRecordDataset\nimage_dataset = tf.data.TFRecordDataset(record_file)\ndebug=1\n\nif debug:\n    parsed_dataset=image_dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n    display_9_images_from_dataset(parsed_dataset) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import http\nhttp.client.HTTPConnection.debuglevel=0                   #set it to 5 for debugging\nSTORAGE_CLIENT = storage.Client(project='panda-285106')   # For uploading to GCS buckets\nWORKING_DIRECTORY = \"./\"                                              \nFILE_PATTERN = data_dir + '/*.tiff'\n\ndef create_bucket(dataset_name):\n    \"\"\"Creates a new bucket. https://cloud.google.com/storage/docs/ \"\"\"\n    bucket = STORAGE_CLIENT.create_bucket(dataset_name)\n    print('Bucket {} created'.format(bucket.name))\n\ndef upload_blob(bucket_name, source_file_name, destination_blob_name):\n    \"\"\"Uploads a file to the bucket. https://cloud.google.com/storage/docs/ \"\"\"\n    bucket = STORAGE_CLIENT.get_bucket(bucket_name)\n    blob = bucket.blob(destination_blob_name, chunk_size=1*1024*1024)    #streaming in 1MB chunks\n    blob.upload_from_filename(source_file_name)\n    print('File {} uploaded to {}.'.format(\n        source_file_name,\n        destination_blob_name))\n    \ndef list_blobs(bucket_name):\n    \"\"\"Lists all the blobs in the bucket. https://cloud.google.com/storage/docs/\"\"\"\n    blobs = STORAGE_CLIENT.list_blobs(bucket_name)\n    for blob in blobs:\n        print(blob.name)\n        \ndef download_to_kaggle(bucket_name,destination_directory,file_name):\n    \"\"\"Takes the data from your GCS Bucket and puts it into the working directory of your Kaggle notebook\"\"\"\n    os.makedirs(destination_directory, exist_ok = True)\n    full_file_path = os.path.join(destination_directory, file_name)\n    blobs = STORAGE_CLIENT.list_blobs(bucket_name)\n    for blob in blobs:\n        blob.download_to_filename(full_file_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bucket_name = 'lvl1-36-256x256'         \ntry:\n    create_bucket(bucket_name)   \nexcept:\n    print('Couldnt create a bucket')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"level=1\nlist_DF=train_labels\naug=0                           #can't augment the validation set\nn_tiles=36\n\nshard_count=50\nshard_size=len(train_list)//shard_count\nprint('',len(train_list),shard_size)\nstart=0\nend=shard_size\n\nfor shard in range(shard_count):\n    tfr_file=\"{}-shard{}.tfrec\".format(bucket_name,shard)\n    record_file = WORKING_DIRECTORY + tfr_file\n    file_list=train_list[start:end]\n    start+= shard_size\n    end += shard_size\n    print(record_file,'n_img: ',len(file_list))\n\n    to_tfrecord(record_file,file_list,level,aug,n_tiles)\n    !du -sh {record_file}\n\n    tic = time.perf_counter()\n    upload_blob(bucket_name, record_file, tfr_file)\n    toc = time.perf_counter()\n    dt  = toc-tic\n    print(f\"Upload took {dt//3600:0.0f} hours {(dt-((dt//3600)*3600))//60:0.0f} minutes {dt%60:0.4f} seconds\\n\")\n    !rm $tfr_file\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"debug=1\n\nif(debug):\n    destination_directory = '/kaggle/working/download/'       \n    download_to_kaggle(bucket_name,destination_directory,tfr_file)\n\n    image_dataset = tf.data.TFRecordDataset(os.path.join(destination_directory,tfr_file))\n    parsed_dataset=image_dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n    display_9_images_from_dataset(parsed_dataset) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}