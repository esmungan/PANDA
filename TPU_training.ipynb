{"cells":[{"metadata":{"_uuid":"8ac9eb93-282a-4b75-a443-2050947fb83e","_cell_guid":"e3e0d494-bdc1-4d21-b6e4-5707056e9f48","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pathlib,os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport skimage.io\nfrom sklearn.model_selection import StratifiedKFold\nimport time\nimport albumentations\nimport tensorflow_addons as tfa\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers,models\n\nAUTO = tf.data.experimental.AUTOTUNE\n\nimport random as python_random\nnp.random.seed(1234)\npython_random.seed(1234)\ntf.random.set_seed(1234)\nos.environ['PYTHONHASHSEED']=str(0)\nSEED=1234\n\nfrom kaggle_datasets import KaggleDatasets\n!pip install -q efficientnet\nimport efficientnet.tfkeras as efn\nfrom tensorflow.keras.models import model_from_json\nfrom sklearn.metrics import cohen_kappa_score\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#GCS_DS_PATH = KaggleDatasets().get_gcs_path('prostate-cancer-grade-assessment') # you can list the bucket with \"!gsutil ls $GCS_DS_PATH\"\nGCS_PATH = 'gs://lvl1-36-256x256'\nshard_num = 50\nfiles=[]\n\nfor i_shard in range(shard_num):\n    file = GCS_PATH + '/lvl1-36-256x256-shard'+str(i_shard)+'.tfrec'\n    files.append(file)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b904a1e0-d4ff-4136-afab-c01777a8fb8b","_cell_guid":"be8e4e77-1ab9-454e-a44d-2ac7a859da96","trusted":true},"cell_type":"code","source":"kaggle_data= '../input/prostate-cancer-grade-assessment'\n\nlabel_dir=kaggle_data+'/train.csv'\ntrain_labels = pd.read_csv(label_dir).set_index('image_id')\nblack_list= ['3790f55cad63053e956fb73027179707','014006841b9807edc0ff277c4ab29b91','00d8a8c04886379e266406fdeff81c45','6f310463d3868e86be87adddeccdde19', '6ef357192c2530ee54e1bd38a3231e00', '511a33b7aeb1153407ed2d55cae001c8', '2fb68d6713a52e322692dbc99ac82444', '8a415b0e974861fa00ae9d88f9e3b980', 'eda92317b583435a810cac1dc7bb8025', 'c9dbdd9c9fc0eab0d235499488b26c53', '99d9afb22b65ea97fcd21ce67e1ddb6c', '0c46c60ae2ef49657bc843707162ba6e', '85b7018a9e5287342a1392fb02ce24a1', '4e80b5738f591c7d0d91889c2bdfd39d', 'f13cd8ec6e6fde523a0a065b62086d3c', 'aebe292567e0f8447fdc94994189a80a', '6b512a45bd8ca759e655c2d551dec2d9', 'be403ce415609008605d63396869ed2e', 'e3360926180928287a4d96973e10926a', '3752b697cae9f81a9d5ffe44dac58e7a', 'a0ac3589042f9e99d31b521b5b56ac06', 'f5675cb89a120e225ca8929b64a5af79', '6d569809f11e6e53918dfb1609fb0d83', '7817ae2d392ba4f6cb9104fbe70b6274', 'cd382fdc26516c634b2314aa870bfe80', '1cdd6def1e3099a9763938457cf0b4be', '0186f4811c9d089707d9dc7460160d88', 'e9d628364cf51891028163e0cfca628c', '9effeea56c413b92340b89d1240769c1', '7a0a36bc6119e3d78474e6c8ca875725', '374d5401159d9bf39ce20b395d82c0b4', '7fa4634ab59a7832bc877fef162eacaa', 'ee182a14e532b122f40d561d87eb2136', 'c0a0956a39319920d02c5c4eb30c5e10', '441265c6b4598e9bcd10bc10eb6293cc', '8ae069858aecbad846f4d69d405f9bd6', 'b13961504ea859ff34a150bc19fed335', '476f0dfb144aee7d5422dcc3b2b97a9f', 'bc93d165d96e4fa4883f130b3f7b9885', 'ac9d05fa3f4fafb474fb96f9f8ab71ac', '1438f19e07c389b47fd5219ca62f9f0a', '479200a381febadfd767615fbe77c3ea', 'fc6a695ba44f4b64425c522f590bac48', '046bac77a58c1be84a6418904e755280', '5c083ab21fc57c0954468ab46aa7fb16', 'cca735c397880e88192e97d68b97754e', 'a579110fe1e670847d9d146404597750', '8dbedd97ed2b7b01525d6800d52ae073', '004dd32d9cd167d9cc31c13b704498af', 'cdf40333dfe2afec1a4c54d9eeb1ec7a', '09d4be69a2330cd49298bf30d29cc4e5', 'f73951fddf77034c9fd44cb19f5fe6b5', 'aef75d4c390d838aabe56e2d601b6a13', 'b3a2dc7547bc580c6f3923c61db42051', '774c9b631a29f191836b1078a6c3a67c', '836ca5d73c88ad94fb980ca3e5e65da7', 'bfdbe56fb7fc4d7b3d151370f897d503', '06ef49a7b77e883f089cfdd80642d6f0', '8e25584bd03155d24a2adc00517a38e8', 'dc2ec851fcbf594f11b023387ac15003', 'a0150f4d6d9f6f3b2b5a240b099df000']\ntrain_labels=train_labels.drop(black_list)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b8f64c2-d273-4c51-bf3a-ae66cb8c8f25","_cell_guid":"9e65b290-a2e5-43a2-a642-2211e816ca4a","trusted":true},"cell_type":"code","source":"def create_folds(train_labels,n_fold, debug=0):\n    input_DF= train_labels.copy().reset_index(drop=False) # drop the image_ID as the index so that the you can index with skf's results\n\n    skf=StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n    for f, (train_idx,test_idx) in enumerate(skf.split(input_DF,input_DF['isup_grade'])):\n        input_DF.loc[test_idx,'test_fold']= f  #setting wrt test data indexes as they don't overlap\n\n    if(debug): display(input_DF)    \n    \n    return input_DF\n\n\n\ndef get_train_val_list(fold, labels_DF,debug=0):\n\n    train_list=[]\n    im_ID_train=labels_DF.loc[labels_DF['test_fold']!=fold,'image_id']\n    for ID in im_ID_train:   train_list.append(ID) # changed from data_simple to data dir\n    if(debug): \n        print('train')\n        for i in train_list[0:2]: print(i)\n        print(\"Num of samples: \",len(train_list),\"\\n\")\n\n    val_list=[]\n    im_ID_test=labels_DF.loc[labels_DF['test_fold']==fold,'image_id']\n    for ID in im_ID_test:   val_list.append(ID)  # changed from data_simple to data dir\n    if(debug): \n        print('test')\n        for i in test_list[0:2]: print(i)\n        print(\"Num of samples: \",len(val_list))\n\n    return train_list, val_list\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_tfrecord(example):\n    features = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n        \"label\": tf.io.FixedLenFeature([], tf.int64),   # shape [] means scalar\n        \"im_ID\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n    }\n    # decode the TFRecord\n    example = tf.io.parse_single_example(example, features)\n    \n    image = tf.image.decode_png(example['image'], channels=0)  \n    image = tf.reverse(image, axis=[-1])\n\n    image = tf.cast(image, tf.float32) / 255.0                # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*[IMAGE_DIM,IMAGE_DIM], 3])               # explicit size needed for TPU\n    \n    \n    label = example['label']\n    im_ID = example['im_ID']\n    return image, label, im_ID\n\ndef load_dataset(filenames, ordered = False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # Diregarding data order. Order does not matter since we will be shuffling the data anyway\n    \n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n        \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # use data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_tfrecord, num_parallel_calls = AUTO) # returns a dataset of (image, label) pairs if labeled = True or (image, id) pair if labeld = False\n    return dataset\n\ndef data_augment(image, label):\n    image = tf.image.random_flip_left_right(image, seed= SEED)\n    tf.image.random_hue(image, max_delta=0.2, seed = SEED)\n    return image, label   \n\n\ndef get_training_dataset(dataset,im_ID_list,do_aug=True):\n    \n    dataset=dataset.filter(lambda image,label,im_ID: tf.reduce_any(tf.equal(im_ID,im_ID_list)) )\n    dataset=dataset.map(lambda image,label,im_ID: [image,label])\n    \n    if do_aug: dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(512)\n    dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\n\ndef get_validation_dataset(val_dataset,im_ID_list):\n\n    val_dataset=val_dataset.filter(lambda image,label,im_ID: tf.reduce_any(tf.equal(im_ID,im_ID_list)) )\n    val_dataset=val_dataset.map(lambda image,label,im_ID: [image,label])\n\n    val_dataset = val_dataset.batch(BATCH_SIZE,drop_remainder=True)\n    val_dataset = val_dataset.cache()\n    val_dataset = val_dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return val_dataset\n\ndef display_9_images_from_dataset(dataset):\n  plt.figure(figsize=(13,13))\n  subplot=331\n  for i, (image, label,im_ID) in enumerate(dataset):\n    plt.subplot(subplot)\n    plt.axis('off')\n    plt.imshow(image.numpy())\n    plt.title(im_ID.numpy().decode(\"utf-8\"), fontsize=14,color='w')\n    subplot += 1\n    if i==8:\n      break\n  plt.tight_layout()\n  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n  plt.show()   ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ea0bbd1-c720-4f1b-b325-1a0ffc8e7736","_cell_guid":"79254308-ef95-4620-9784-d23f93e139d7","trusted":true},"cell_type":"code","source":"LR_START = 0.0005\nLR_MAX = 0.00025 * strategy.num_replicas_in_sync\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 5\nLR_SUSTAIN_EPOCHS = 0\nLR_EXP_DECAY = .8\n\ndef warm_up(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \n\ndef define_model(IMAGE_DIM):\n    enet = efn.EfficientNetB0(\n            input_shape=(IMAGE_DIM,IMAGE_DIM,3),\n            weights='imagenet',\n            include_top=False,\n            pooling='max'\n        )\n    enet.trainable = True\n    \n    model = tf.keras.Sequential([\n        enet,\n        tf.keras.layers.Dense(6, kernel_regularizer=tf.keras.regularizers.l2(0.01))\n    ])\n    \n\n    model.compile(\n      optimizer=tf.keras.optimizers.Adam(),\n      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n      metrics=['sparse_categorical_accuracy']\n    )\n    \n    return model\n\n\ndef run_training(model,train_batches,test_batches,n_epochs,steps_per_epoch):\n\n    tic = time.perf_counter()\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(warm_up, verbose=True)\n    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3)\n\n    history = model.fit(train_batches, epochs=n_epochs, validation_data=val_batches, steps_per_epoch=steps_per_epoch, callbacks=[lr_callback,early_stop])\n\n    toc = time.perf_counter()\n    dt  = toc-tic\n    print(f\"Operation took {dt//3600:0.0f} hours {(dt-((dt//3600)*3600))//60:0.0f} minutes {dt%60:0.4f} seconds\\n\")\n    \n    return model, history\n\ndef save_json_and_weights(model_name,fold):\n    json_file=model_name+'_fold'+str(fold)+'.json'\n    weight_file=model_name+'_fold'+str(fold)+'.h5'\n\n    model_json = efnet_b0.to_json()\n    with open(json_file, \"w\") as json_handle:\n        json_handle.write(model_json)\n\n    efnet_b0.save_weights(weight_file)\n    print(\"Saved \"+model_name+\" model to disk\")\n    \n    \ndef load_json_and_weights(model_name,fold):\n    \n    json_file=model_name+'_fold'+str(fold)+'.json'\n    weight_file=model_name+'_fold'+str(fold)+'.h5'\n    \n    \n    with open(json_file, \"r\") as json_handle:\n        loaded_model_json= json_handle.read()\n    \n    loaded_model = model_from_json(loaded_model_json)\n    loaded_model.compile(\n        optimizer=tf.keras.optimizers.Adam(),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=['sparse_categorical_accuracy']\n        #metrics=[tfa.metrics.CohenKappa(weightage='quadratic', num_classes=6,sparse_labels=True),'sparse_categorical_accuracy' ]\n    )\n    \n    if (os.path.exists(weight_file)):\n        loaded_model.load_weights(weight_file)\n    \n    print(\"Loaded \"+model_name+\" model from disk\")\n    \n    return loaded_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_DS=0  # debugging flag for datasets\n\nn_fold=5\nfold=0\nIMAGE_DIM=1536\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\n\n\nif(check_DS):\n\n    input_DF=create_folds(train_labels,n_fold)\n    train_list, val_list = get_train_val_list(fold, input_DF, debug=0)\n\n    #train_batches = get_training_dataset(load_dataset(files,ordered=False),im_ID_list= train_list, do_aug=aug).unbatch()\n    val_batches   = get_validation_dataset(load_dataset(files,ordered=False),im_ID_list= val_list).unbatch()\n\n    #display_9_images_from_dataset(all_images)\n\n    #for i, (image, label) in enumerate(train_batches):   pass #doesn't work if DS is repeated!!\n    #print(i)\n\n    for i, (image, label) in enumerate(val_batches):   pass #doesn't work if DS is repeated!!\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0f8de6c-ecc4-40c3-868f-b6df8dc616c7","_cell_guid":"2126fa72-1d31-40c9-b4f3-a28f8fa19677","trusted":true},"cell_type":"code","source":"n_fold=5\ndebug=0\naug=True\ninput_dim= 1536\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMAGE_DIM = 1536\nmodel_name='efnet_b0'\n\n\nn_epochs=25\n\n\n\ninput_DF=create_folds(train_labels,n_fold)\n\nfor fold in range(0,1):\n    print(\"\\n\\nFOLD \"+str(fold)+\"\\n\\n\")\n    tic = time.perf_counter()\n\n    train_list, val_list = get_train_val_list(fold, input_DF, debug)\n    steps_per_epoch = len(train_list)//BATCH_SIZE\n    \n    train_batches = get_training_dataset(load_dataset(files,ordered=False),im_ID_list= train_list, do_aug=aug)\n    val_batches   = get_validation_dataset(load_dataset(files,ordered=False),im_ID_list= val_list)\n    \n    print(\"Starting training\")\n    with strategy.scope():\n        efnet_b0 = define_model(IMAGE_DIM)\n    \n    efnet_b0,history= run_training(efnet_b0,train_batches,val_batches,n_epochs,steps_per_epoch)\n\n    toc = time.perf_counter()\n    dt  = toc-tic\n    print(f\"Training took {dt//3600:0.0f} hours {(dt-((dt//3600)*3600))//60:0.0f} minutes {dt%60:0.4f} seconds\\n\")\n    \n    save_json_and_weights(model_name,fold)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check whether model is saved\n\nloaded_model= load_json_and_weights(model_name,fold)\n\nresults = loaded_model.evaluate(val_batches,batch_size= BATCH_SIZE)\nprint(\"test loss, test acc:\", results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tic = time.perf_counter()\n\nval_batches_ordered = get_validation_dataset(load_dataset(files,ordered=True),im_ID_list= val_list)\n\npred = loaded_model.predict(val_batches_ordered)\npred_probs= np.argmax(pred, axis = 1)\n\ntoc = time.perf_counter()\ndt  = toc-tic\nprint(f\"Prediction took {dt//3600:0.0f} hours {(dt-((dt//3600)*3600))//60:0.0f} minutes {dt%60:0.4f} seconds\\n\")\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels=[]\nfor image,label in val_batches_ordered.unbatch():\n    labels.append(label)\n\nactuals=np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kappa = cohen_kappa_score(actuals, pred_probs, labels=None, weights= 'quadratic', sample_weight=None)\nprint('\\nValid Cohen\\'s Kappa : {}'.format(kappa))\nprint(tf.math.confusion_matrix(actuals, pred_probs, num_classes=6, weights=None, dtype=tf.dtypes.int32,name=None).numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}