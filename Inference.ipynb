{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference Notebook**\n",
    "\n",
    "Due to computation time limit on the final submission notebook, inference and training notebooks have been seperated. \n",
    "\n",
    "This notebook makes inference using the trained model and calculates the Cohen's Kappa which is the figure of merit for this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "import tensorflow as tf\n",
    "import pathlib,os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "import albumentations\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers,models\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import random as python_random\n",
    "np.random.seed(123)\n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(1234)\n",
    "os.environ['PYTHONHASHSEED']=str(0)\n",
    "\n",
    "#from keras import backend as K\n",
    "#session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "#sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "#K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "kaggle_data= '/data/users/rpravahan/panda'\n",
    "\n",
    "data_dir=kaggle_data+'/train_images'\n",
    "data_simple_dir='/home/emungan/panda/data_simple/images'\n",
    "ds_dir = pathlib.Path(data_simple_dir)\n",
    "\n",
    "label_dir=kaggle_data+'/train.csv'\n",
    "train_labels = pd.read_csv(label_dir).set_index('image_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tiff(img_path_tensor,level):      \n",
    "    \n",
    "    #read the image \n",
    "    img_path = img_path_tensor.numpy().decode(\"utf-8\")     #input needs to be a tensor, skimage wants a string to iterate over\n",
    "    img      = skimage.io.MultiImage(str(img_path))[level]\n",
    "    im_ID    = img_path.split(os.sep)[-1].split('.')[0]\n",
    "\n",
    "    return img\n",
    "\n",
    "def augment(image_array):\n",
    "    \n",
    "    # Augmentations    \n",
    "    op_train = albumentations.Compose([\n",
    "        albumentations.VerticalFlip(p=0.5),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.Rotate(limit=90,border_mode=4,p=0.5),    #mode 1 wraps around\n",
    "        #albumentations.ElasticTransform(alpha=1, sigma=50, alpha_affine=50,p=0.5),\n",
    "        albumentations.HueSaturationValue(hue_shift_limit=(0,20), sat_shift_limit=0, val_shift_limit=0,p=0.5),\n",
    "        #albumentations.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20,p=0.5),\n",
    "        albumentations.GaussianBlur(blur_limit=3,p=0.25)\n",
    "    ])  \n",
    "    \n",
    "    return op_train(image=image_array)['image']        \n",
    "\n",
    "\n",
    "def tile_tiff(img,level,n_tiles):\n",
    "    # get the patches with tissue    \n",
    "    \n",
    "    if (level==1): tile_size=256                          # tile size depends on the downsampling of the level\n",
    "    elif (level == 2): tile_size =128\n",
    "    else: raise Exception(\"level is not 1 or 2\")\n",
    "    \n",
    "    mode=0\n",
    "    sub_imgs=False\n",
    "    is_rand=False\n",
    "    \n",
    "    tiles = []\n",
    "    h, w, c = img.shape\n",
    "    pad_h = (tile_size - h % tile_size) % tile_size + ((tile_size * mode) // 2)\n",
    "    pad_w = (tile_size - w % tile_size) % tile_size + ((tile_size * mode) // 2)\n",
    "\n",
    "    img2 = np.pad(img,[[pad_h // 2, pad_h - pad_h // 2], [pad_w // 2,pad_w - pad_w//2], [0,0]], constant_values=255)\n",
    "    img3 = img2.reshape(img2.shape[0] // tile_size,tile_size,img2.shape[1] // tile_size,tile_size, 3)\n",
    "    \n",
    "    img3 = img3.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size,3)\n",
    "    n_tiles_with_info = (img3.reshape(img3.shape[0],-1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n",
    "    if len(img) < n_tiles:\n",
    "        img3 = np.pad(img3,[[0,N-len(img3)],[0,0],[0,0],[0,0]], constant_values=255)\n",
    "    idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:n_tiles]\n",
    "    img3 = img3[idxs]\n",
    "    for i in range(len(img3)):\n",
    "        tiles.append({'img':img3[i], 'idx':i})\n",
    "    \n",
    "    # create the patchwork  \n",
    "    if is_rand:\n",
    "        idxes = np.random.choice(list(range(n_tiles)), n_tiles, replace=False)\n",
    "    else:\n",
    "        idxes = list(range(n_tiles))\n",
    "    idxes = np.asarray(idxes) + n_tiles if sub_imgs else idxes\n",
    "\n",
    "    n_row_tiles = int(np.sqrt(n_tiles))\n",
    "    images = np.zeros((tile_size * n_row_tiles, tile_size * n_row_tiles, 3))\n",
    "    for h in range(n_row_tiles):\n",
    "        for w in range(n_row_tiles):\n",
    "            i = h * n_row_tiles + w\n",
    "    \n",
    "            if len(tiles) > idxes[i]:\n",
    "               this_img = tiles[idxes[i]]['img']\n",
    "            else:\n",
    "                this_img = np.ones((tile_size, tile_size, 3)).astype(np.uint8) * 255\n",
    "            this_img = 255 - this_img\n",
    "            h1 = h * tile_size\n",
    "            w1 = w * tile_size\n",
    "            images[h1:h1+tile_size, w1:w1+tile_size] = this_img\n",
    "\n",
    "    images = 255 - images\n",
    "    images = images.astype(np.float32)\n",
    "    images /= 255                                              # no need to normalize later\n",
    "    \n",
    "    return images\n",
    "    \n",
    "def tile_and_aug_tiff(img_path_tensor,level,aug,n_tiles):      # combining three python functions to be wrapped\n",
    "    \n",
    "    #read \n",
    "    img = read_tiff(img_path_tensor,level)\n",
    "    \n",
    "    # Augment the image\n",
    "    if(aug): img= augment(img)\n",
    "\n",
    "    # get the patches with tissue    \n",
    "    images=tile_tiff(img,level,n_tiles)\n",
    "    \n",
    "    return images\n",
    "\n",
    "def tile_aug_tiff(image_path,level,aug,n_tiles):  #inputs should be tensors\n",
    "    \n",
    "    [image,] = tf.py_function(tile_and_aug_tiff,[image_path,level,aug,n_tiles],[tf.float32])\n",
    "    im_shape = image.shape\n",
    "    image.set_shape(im_shape)\n",
    "    \n",
    "    return image  \n",
    "\n",
    "\n",
    "@tf.autograph.experimental.do_not_convert   # ow gives out a lot of warnings..\n",
    "def create_batches(path_list, level, subset_ratio, batch_size,n_tiles, tiled_input=1, debug=0, aug=0):\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(path_list,tf.string))\n",
    "    if (debug): list(dataset.as_numpy_iterator())  \n",
    "    \n",
    "    if(tiled_input):\n",
    "        batches = (\n",
    "            dataset\n",
    "            .cache()\n",
    "            #.shuffle(len(path_list))  \n",
    "            .take(int(len(path_list)*subset_ratio))\n",
    "            .map(lambda x: tile_aug_tiff(x,tf.constant(level),tf.constant(aug),tf.constant(n_tiles)),num_parallel_calls=AUTOTUNE )\n",
    "            .batch(batch_size)\n",
    "            .prefetch(AUTOTUNE)\n",
    "        )\n",
    "    \n",
    "    return batches   \n",
    "\n",
    "def path_list(hold_out_DF,test_path,debug):\n",
    "    \n",
    "    hold_out_paths = []\n",
    "    im_ID_ho = hold_out_DF.loc[:,'image_id']\n",
    "    for ID in im_ID_ho:   hold_out_paths.append(os.path.join(test_path,ID+'.tiff')) # changed from data_simple to data dir\n",
    "    if(debug): \n",
    "        print('holdout')\n",
    "        for i in hold_out_paths[0:2]: print(i)\n",
    "        print(\"Num of samples: \",len(hold_out_paths),\"\\n\")   \n",
    "    \n",
    "    return hold_out_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keras_model(model_filepath):\n",
    "    model = tf.keras.models.load_model(\n",
    "        model_filepath,\n",
    "        custom_objects=None,\n",
    "        compile=True\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/users/rpravahan/panda/train_images\n",
      "(10616, 4)\n",
      "Test path exists:  /data/users/rpravahan/panda/train_images\n",
      "holdout\n",
      "/data/users/rpravahan/panda/train_images/0005f7aaab2800f6170c399693a96917.tiff\n",
      "/data/users/rpravahan/panda/train_images/000920ad0b612851f8e01bcc880d9b3d.tiff\n",
      "Num of samples:  10616 \n",
      "\n",
      "Predict for 10616 images\n",
      "image_id,isup_grade,gleason_score\n",
      "0005f7aaab2800f6170c399693a96917,0,0+0\n",
      "000920ad0b612851f8e01bcc880d9b3d,0,0+0\n",
      "0018ae58b01bdadc8e347995b69f99aa,4,4+4\n",
      "001c62abd11fa4b57bf7a6c603a11bb9,5,4+4\n",
      "001d865e65ef5d2579c190a0e0350d8f,0,0+0\n",
      "002a4db09dad406c85505a00fb6f6144,1,0+0\n",
      "003046e27c8ead3e3db155780dc5498e,0,3+3\n",
      "0032bfa835ce0f43a92ae0bbab6871cb,1,3+3\n",
      "003a91841da04a5a31f808fb5c21538a,1,3+3\n"
     ]
    }
   ],
   "source": [
    "level=2                        \n",
    "batch_size=16\n",
    "subset_ratio=1                 # can use a subset of the training data\n",
    "tiled_input=1                  # image is tiled instead of cropped and padded\n",
    "n_tiles=25\n",
    "debug=1\n",
    "aug=0\n",
    "\n",
    "\n",
    "if(level==1):    input_dimx= int((n_tiles**0.5)*256)\n",
    "elif(level==2):  input_dimx= int((n_tiles**0.5)*128)\n",
    "else:            raise Exception(\"level is not 1 or 2\")\n",
    "input_dimy=input_dimx\n",
    "\n",
    "model_filepath ='/home/emungan/panda/saved_models/KFold_fold0'\n",
    "\n",
    "loaded_model = load_keras_model(model_filepath)\n",
    "\n",
    "if (debug):\n",
    "    hold_out_DF = pd.read_csv('{}/train.csv'.format(kaggle_data))\n",
    "#    hold_out_DF=hold_out_DF[0:1000]\n",
    "    test_path=data_dir\n",
    "    print(test_path)\n",
    "    \n",
    "else:\n",
    "    hold_out_DF = pd.read_csv('{}/test.csv'.format(kaggle_data))\n",
    "\n",
    "print(hold_out_DF.shape)\n",
    "pred = np.zeros((len(hold_out_DF), 6))\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    if os.path.exists(test_path):\n",
    "        print('Test path exists: ',test_path)\n",
    "        hold_out_paths = path_list(hold_out_DF,test_path,debug)\n",
    "        hold_out_batch = create_batches(hold_out_paths, level, subset_ratio, batch_size,n_tiles, tiled_input, debug=debug, aug=0)\n",
    "        pred = loaded_model.predict(hold_out_batch)\n",
    "        print('Predict for {} images'.format(len(pred)))\n",
    "    else:\n",
    "        print('No test path. Predict zeros')    \n",
    "\n",
    "if (debug): actuals=np.array(hold_out_DF['isup_grade'])\n",
    "\n",
    "hold_out_DF['isup_grade'] = np.argmax(pred, axis = 1)\n",
    "hold_out_DF.drop('data_provider', axis = 1, inplace = True)\n",
    "hold_out_DF.to_csv('submission.csv', index = False)\n",
    "!head /home/emungan/panda/codes/submission.csv\n",
    "\n",
    "if (debug): train_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa:  0.7503367\n"
     ]
    }
   ],
   "source": [
    "if(debug):\n",
    "    pred_probs= np.argmax(pred, axis = 1)\n",
    "    m = tfa.metrics.CohenKappa(weightage='quadratic', num_classes=6,sparse_labels=True)\n",
    "    m.update_state(actuals, pred_probs)\n",
    "    print('Cohen\\'s Kappa: ', m.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2761   68    2   45    2   14]\n",
      " [ 796 1662  125   59    5   19]\n",
      " [ 162  538  385  202   24   32]\n",
      " [ 141  116  112  586  116  171]\n",
      " [ 213   61   44  273  354  304]\n",
      " [ 143    9    7  224  108  733]]\n"
     ]
    }
   ],
   "source": [
    "if(debug): \n",
    "    confusion=tf.math.confusion_matrix(actuals, pred_probs, num_classes=6, weights=None, dtype=tf.dtypes.int32,name=None ).numpy()\n",
    "    print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95 0.03 0.   0.04 0.   0.01]\n",
      " [0.28 0.62 0.09 0.05 0.   0.02]\n",
      " [0.06 0.2  0.29 0.16 0.02 0.03]\n",
      " [0.05 0.04 0.08 0.47 0.09 0.14]\n",
      " [0.07 0.02 0.03 0.22 0.28 0.25]\n",
      " [0.05 0.   0.01 0.18 0.09 0.6 ]]\n"
     ]
    }
   ],
   "source": [
    "confusion_ratio= np.asarray(np.around(confusion/np.sum(confusion,axis=1),2))\n",
    "print(confusion_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy for class 0 is 0.95\n",
      "Prediction accuracy for class 1 is 0.62\n",
      "Prediction accuracy for class 2 is 0.29\n",
      "Prediction accuracy for class 3 is 0.47\n",
      "Prediction accuracy for class 4 is 0.28\n",
      "Prediction accuracy for class 5 is 0.6\n"
     ]
    }
   ],
   "source": [
    "class_prediction_acc=np.diag(confusion_ratio)\n",
    "for isup in range(6):\n",
    "    print(\"Prediction accuracy for class {} is {}\".format(isup,class_prediction_acc[isup]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model classifies the healthy samples the best. ISUP grades for 1 and 5 are classified similarly ok but it doesn't work well for grades 2 and 4 at all.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
